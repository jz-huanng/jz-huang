{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### setup"
      ],
      "metadata": {
        "id": "S09Sl1kGLn8n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive') # 此處需要登入google帳號\n",
        "\n",
        "!git clone https://github.com/IKMLab/NCKU-AICUP2023-baseline\n",
        "%cd NCKU-AICUP2023-baseline\n",
        "!cp -r /content/gdrive/MyDrive/aicup-2023-plain/* ."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yPNnt2uEQKgV",
        "outputId": "4706e330-64ae-41e9-dc84-0cf3b4efa8f8"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n",
            "Cloning into 'NCKU-AICUP2023-baseline'...\n",
            "remote: Enumerating objects: 146, done.\u001b[K\n",
            "remote: Counting objects: 100% (45/45), done.\u001b[K\n",
            "remote: Compressing objects: 100% (23/23), done.\u001b[K\n",
            "remote: Total 146 (delta 34), reused 30 (delta 22), pack-reused 101\u001b[K\n",
            "Receiving objects: 100% (146/146), 82.78 KiB | 4.14 MiB/s, done.\n",
            "Resolving deltas: 100% (85/85), done.\n",
            "/content/NCKU-AICUP2023-baseline\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cIUoNn0YM7SU",
        "outputId": "66d30ce4-fe99-46b3-f763-fa31dd5e0a87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.6/73.6 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "#!pip install -q ipywidgets pandarallel pandas scikit-learn tqdm opencc wikipedia\n",
        "!pip install -q pandas wikipedia\n",
        "!pip -q install openai langchain #huggingface_hub"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from pathlib import Path\n",
        "import os\n",
        "\n",
        "# 3rd party libs\n",
        "import pandas as pd\n",
        "import wikipedia\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = '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'\n",
        "wikipedia.set_lang(\"zh\")\n",
        "\n",
        "import langchain\n",
        "langchain.debug=False\n"
      ],
      "metadata": {
        "id": "Pibak_jWNEbr"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### functions(wiki...)"
      ],
      "metadata": {
        "id": "tmsC7j7sLdPR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_json(file_path):\n",
        "    with open(file_path, \"r\", encoding=\"utf8\") as json_file:\n",
        "        json_list = list(json_file)\n",
        "    return [json.loads(json_str) for json_str in json_list]\n",
        "\n",
        "def wiki_database(path):\n",
        "\t\tdatabase=pd.concat(\n",
        "        [pd.DataFrame(load_json(file)) for file in Path(path).glob(\"*.jsonl\")]\n",
        "    )\n",
        "\t\treturn dict(zip(database[\"id\"].tolist(),database[\"text\"].tolist()))\n",
        "\n",
        "def get_wiki_text(wiki,key_word):\n",
        "    try:\n",
        "      text=wiki[key_word]\n",
        "    except KeyError:\n",
        "      text=\"KeyError\"\n",
        "    return text\n"
      ],
      "metadata": {
        "id": "DWgEnUIBPmGW"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "WIKI_PATH=\"data/wiki-pages\"\n",
        "\n",
        "wiki=wiki_database(WIKI_PATH)"
      ],
      "metadata": {
        "id": "qVlFZ_eQqcl_"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Build chains"
      ],
      "metadata": {
        "id": "ubyVZcs1NpnM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models.openai import ChatOpenAI\n",
        "from langchain.chains import LLMChain\n",
        "from langchain import PromptTemplate\n",
        "\n",
        "#text-davinci-003\n",
        "MODEL_NAME=\"gpt-3.5-turbo-16k-0613\"\n",
        "llm = ChatOpenAI(model_name=MODEL_NAME, temperature=1.2, max_tokens = 4096)\n",
        "\n",
        "from langchain.prompts.chat import (\n",
        "    ChatPromptTemplate,\n",
        "    SystemMessagePromptTemplate,\n",
        "    AIMessagePromptTemplate,\n",
        "    HumanMessagePromptTemplate,\n",
        ")\n",
        "from langchain.schema import AIMessage, HumanMessage, SystemMessage\n"
      ],
      "metadata": {
        "id": "08DLt9OzNHH1"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyChain(LLMChain):\n",
        "\n",
        "    @classmethod\n",
        "    def from_llm_and_prompt(cls,llm,prompt,verbose=False):\n",
        "        return cls(prompt=prompt, llm=llm, verbose=verbose)"
      ],
      "metadata": {
        "id": "wNZUsAejHC8n"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EvidenceRetrivalBot(LLMChain):\n",
        "    \"\"\"implenment agent concept via chain class\"\"\"\n",
        "\n",
        "    @classmethod\n",
        "    def from_llm_and_prompt(cls,llm,prompt,verbose=False):\n",
        "        return cls(prompt=prompt, llm=llm, verbose=verbose)"
      ],
      "metadata": {
        "id": "R_LaL3bFOhtH"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import PromptTemplate\n",
        "\n",
        "doc_retrieval_template = \"\"\"\n",
        "你是一個看過維基百科內容的機器人，讓我們來預測以下提供的陳述句可能的出處。請從陳述句中選擇一個單字作為檢索的關鍵字。\n",
        "\n",
        "claim:{claim}\n",
        "\n",
        "按照以下格式返回預測的關鍵詞\n",
        "keyword:\n",
        "\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"claim\"],\n",
        "    template=doc_retrieval_template,\n",
        ")\n",
        "\n",
        "doc_chain=MyChain.from_llm_and_prompt(llm=llm,prompt=prompt)\n"
      ],
      "metadata": {
        "id": "oaUakMO5Nv0c"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evidence_selection_template = \"\"\"\n",
        "陳述句:{claim}\n",
        "以檢索的證據句:{evidence}\n",
        "文章:{text}\n",
        "\n",
        "目前正在檢索的文章是:{keyword}\n",
        "\n",
        "現在要完成的是事實查核任務：從文章中找出與陳述句相關的句子，也有可能文章中不存在相關的句子。如果文章中的句子沒有陳述句的完整信息，請依照缺失的信息決定下一步需要檢索的文章(文章名稱必須是維基百科頁面，名詞)在思考下一步需要檢索的文章請記得不要是當前檢索的文章(當前檢索的文章名稱是什麼？)。如果思考證據句缺失的信息無法經由檢索其他文章中的句子完成任務則標籤為\"資訊不足\"\n",
        "\n",
        "先完成以上步驟給出思考過程。最後整理答案按照以下格式根據指示輸出：\n",
        "evidence:輸出所有證據句，包含已檢索的證據句以及從文章中檢索得到的證據句。並且不要使用: 數字 以及 · 以及 \\n 來區分每一句話。\n",
        "doc:下一步需要檢索的文章，如果不再進行檢索其他文章則為\"None\"，如果缺失的信息無法經由檢索其他文章中的句子完成任務則標籤為\"Not enough info\"。\n",
        "state:如果需要繼續檢索其他文章則狀態為\"continue\"，如果已經找齊所有證據句則狀態為\"finish\"。\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "human_message_prompt = HumanMessagePromptTemplate(\n",
        "        prompt=PromptTemplate(\n",
        "            template=evidence_selection_template,\n",
        "            input_variables=[\"claim\",\"evidence\",\"text\",\"keyword\"],\n",
        "        )\n",
        "    )\n",
        "agent_planning = ChatPromptTemplate.from_messages([human_message_prompt,SystemMessage(\n",
        "        content=\"You are ChatGPT,s large language model trained by OpenAI.\\nKnowledge cutoff:2021-09\\nCurrent data:[current date]\\n\"\n",
        "    )])\n",
        "\n",
        "agent=EvidenceRetrivalBot.from_llm_and_prompt(llm=llm, prompt=agent_planning,verbose=True)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "MPzxSj83Oumw"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "claim_retrieval_template = \"\"\"\n",
        "根據| |前後的雙引號\"\"包圍的一組證據句以及\"\"包圍的陳述句，按照以下步驟以及要求，選擇使用 支持/反駁/資訊不足 來完成三分類任務\n",
        "\n",
        "一、從陳述句和證據句當中抽取出可以互相對應對應的單詞。\n",
        "\n",
        "二、接著檢出每一個對應的單詞，如果含義無法成功匹配，則視為關鍵詞。\n",
        "\n",
        "三、檢查證據句的關鍵詞是否有蘊含陳述句當中的關鍵詞，如果關鍵詞的含義不等同則視為反駁。不等同的狀況請參考以下但不限於以下範例：\"含義明顯衝突、無法經由推論得出結論、蘊含關係不明確。\"參考以上範例根據提供的句子做出合理的判斷。\n",
        "\n",
        "\"{evidence}\"| |\"{claim}\"\n",
        "\n",
        "根據上下文| |應填入 支持/反駁/資訊不足 ？\n",
        "\"\"\"\n",
        "human_message_prompt = HumanMessagePromptTemplate(\n",
        "        prompt=PromptTemplate(\n",
        "            input_variables=[\"claim\",\"evidence\"],\n",
        "            template=claim_retrieval_template,\n",
        "        )\n",
        "    )\n",
        "claim_retrieval = ChatPromptTemplate.from_messages([human_message_prompt,SystemMessage(\n",
        "        content=\"You are ChatGPT,s large language model trained by OpenAI.\\nKnowledge cutoff:2021-09\\nCurrent data:[current date]\\n\"\n",
        "    )])\n",
        "\n",
        "claimRetrieval=MyChain.from_llm_and_prompt(llm=llm, prompt=claim_retrieval,verbose=True)\n"
      ],
      "metadata": {
        "id": "mqS9JSqiQvme"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### main"
      ],
      "metadata": {
        "id": "Ke342oxSfiOp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "font ref:https://blog.csdn.net/c_lanxiaofang/article/details/126107796"
      ],
      "metadata": {
        "id": "9YEn1L-9Kavx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def keywordParser(keywords):\n",
        "    #\\s | Matches whitespace characters, which include the \\t, \\n, \\r, and space characters.\n",
        "    PATTERN=re.compile(r\"(K|k)eywords?\\s*:?\\s*\\'*\\\"*\")\n",
        "    keyword=re.split(PATTERN,keywords)[-1]\n",
        "    return keyword\n",
        "\n",
        "def getAction(response):\n",
        "    PARSER_START = \"evidence:\"\n",
        "    # find(f'\"{self.generation_marker}\"')\n",
        "    start_parsing = response.find(f\"{PARSER_START}\")\n",
        "    if (start_parsing != -1):\n",
        "        reponse = response[start_parsing:]\n",
        "\n",
        "    #LABEL_START_MARKER = \"label:\"\n",
        "    DOC_START_MARKER = \"doc:\"\n",
        "    STATE_START_MARKER = \"state:\"\n",
        "\n",
        "    #label_start = response.find(LABEL_START_MARKER)\n",
        "    doc_start = response.find(DOC_START_MARKER)\n",
        "    state_start = response.find(STATE_START_MARKER)\n",
        "\n",
        "    evidence = response[:doc_start]\n",
        "    evidence = evidence.split(\"evidence: \")[-1].strip()\n",
        "    #label = response[label_start:doc_start]\n",
        "    #label = re.split(r\"label:\\n*\\t*\\s*\", label)[-1].strip()\n",
        "    doc = response[doc_start:state_start]\n",
        "    doc = re.split(r\"doc:\\\"*\\n*\\t*\\s*\", doc)[-1].split(\"或\")[0].strip()\n",
        "    state = response[state_start:]\n",
        "\n",
        "    state = re.split(r\"state:\\n*\\t*\\s*\", state)[-1].split(\"\\n\")[0]\n",
        "\n",
        "    return evidence, doc, state\n"
      ],
      "metadata": {
        "id": "6sQKzUMNeP3I"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def refreshState():\n",
        "\t\tdoc=\"None\"\n",
        "\t\tstate=\"None\"\n",
        "\t\treturn doc,state"
      ],
      "metadata": {
        "id": "wkVbocuNQJ3J"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"***************************************************\")\n",
        "claim=claim=input(\"請輸入一個陳述句:\")\n",
        "\n",
        "text=\"KeyError\"\n",
        "evidence=\"需要從以下文章中檢索\"\n",
        "\n",
        "while(text==\"KeyError\"):\n",
        "    keywords=doc_chain.run(claim)\n",
        "    keyword=keywordParser(keywords)\n",
        "    text=get_wiki_text(wiki,keyword)\n",
        "\n",
        "while True:\n",
        "    doc,state=refreshState()\n",
        "    response=agent.run(claim=claim,evidence=evidence,keyword=keyword,text=text)\n",
        "    print(\"\\033[91m\\033[1m\" ,response, \"\\033[0m\\033[0m\")\n",
        "    evidence,doc,state=getAction(response)\n",
        "\n",
        "    IS_FINISH=(state==\"finish\" and doc==\"None\")\n",
        "    #NOT_ENOUGH_INFO=(label==\"not enough info\" or doc==keyword)\n",
        "    NOT_ENOUGH_INFO=(doc==keyword or doc==\"Not enough info\")\n",
        "    IS_CONTINUE=(state==\"continue\")\n",
        "\n",
        "    if IS_FINISH:\n",
        "        answer=claimRetrieval.run(claim=claim,evidence=evidence)\n",
        "        print(\"\\033[96m\\033[1m\" ,answer, \"\\033[0m\\033[0m\")\n",
        "        break\n",
        "\n",
        "    if NOT_ENOUGH_INFO:\n",
        "        print(\"\\033[90m\\033[1m\" + \"claim:\",claim,\"is NOT ENOUGH INFO\" \"\\033[0m\\033[0m\")\n",
        "        break\n",
        "\n",
        "    if IS_CONTINUE:\n",
        "        if wiki[doc]!=\"KeyError\":\n",
        "            text=wiki[doc]\n",
        "        #evidence=evidence\n",
        "        continue\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "00kBB3Diet93",
        "outputId": "63feb9f1-657d-4cc8-ec4c-6308e3baf53a"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "***************************************************\n",
            "請輸入一個陳述句:威廉·華茲華斯是生活在英格蘭湖區的民意代表。\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new EvidenceRetrivalBot chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mHuman: \n",
            "陳述句:威廉·華茲華斯是生活在英格蘭湖區的民意代表。\n",
            "以檢索的證據句:需要從以下文章中檢索\n",
            "文章:威廉 · 華茲渥斯 （ William Wordsworth ) ， 英國浪漫主義詩人 ， 與雪萊 、 拜倫齊名 ， 也是湖畔詩人的代表 ， 曾當上桂冠詩人 。 其代表作有與塞繆爾 · 泰勒 · 柯勒律治合著的 《 抒情歌謠集 》 、 長詩 《 序曲 》 （ Prelude ） 、 《 漫遊 》 （ Excursion ） 。\n",
            "\n",
            "目前正在檢索的文章是:威廉·華茲華斯\n",
            "\n",
            "現在要完成的是事實查核任務：從文章中找出與陳述句相關的句子，也有可能文章中不存在相關的句子。如果文章中的句子沒有陳述句的完整信息，請依照缺失的信息決定下一步需要檢索的文章(文章名稱必須是維基百科頁面，名詞)在思考下一步需要檢索的文章請記得不要是當前檢索的文章(當前檢索的文章名稱是什麼？)。如果思考證據句缺失的信息無法經由檢索其他文章中的句子完成任務則標籤為\"資訊不足\"\n",
            "\n",
            "先完成以上步驟給出思考過程。最後整理答案按照以下格式根據指示輸出：\n",
            "evidence:輸出所有證據句，包含已檢索的證據句以及從文章中檢索得到的證據句。並且不要使用: 數字 以及 · 以及 \n",
            " 來區分每一句話。\n",
            "doc:下一步需要檢索的文章，如果不再進行檢索其他文章則為\"None\"，如果缺失的信息無法經由檢索其他文章中的句子完成任務則標籤為\"Not enough info\"。\n",
            "state:如果需要繼續檢索其他文章則狀態為\"continue\"，如果已經找齊所有證據句則狀態為\"finish\"。\n",
            "\n",
            "System: You are ChatGPT,s large language model trained by OpenAI.\n",
            "Knowledge cutoff:2021-09\n",
            "Current data:[current date]\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\u001b[91m\u001b[1m Evidence:\n",
            "1. \"威廉 · 華茲渥斯 （ William Wordsworth ) ， 英國浪漫主義詩人 ， 與雪萊 、 拜倫齊名 ， 也是湖畔詩人的代表\"\n",
            "2. \"曾當上桂冠詩人。\"\n",
            "3. \"其代表作有與塞繆爾 · 泰勒 · 柯勒律治合著的 《 抒情歌謠集 》、長詩《序曲》（Prelude）、《漫遊》（Excursion）。\n",
            "\n",
            "According to the evidence, William Wordsworth is mentioned in the text, but there isn't enough information to confirm if he is a representative of the people living in the Lake District of England. Hence, the task cannot be completed with the given evidence, and we need to search for another article.\n",
            "\n",
            "Doc: Lake District\n",
            "State: continue \u001b[0m\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new EvidenceRetrivalBot chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mHuman: \n",
            "陳述句:威廉·華茲華斯是生活在英格蘭湖區的民意代表。\n",
            "以檢索的證據句:Evidence:\n",
            "1. \"威廉 · 華茲渥斯 （ William Wordsworth ) ， 英國浪漫主義詩人 ， 與雪萊 、 拜倫齊名 ， 也是湖畔詩人的代表\"\n",
            "2. \"曾當上桂冠詩人。\"\n",
            "3. \"其代表作有與塞繆爾 · 泰勒 · 柯勒律治合著的 《 抒情歌謠集 》、長詩《序曲》（Prelude）、《漫遊》（Excursion）。\n",
            "\n",
            "According to the evidence, William Wordsworth is mentioned in the text, but there isn't enough information to confirm if he is a representative of the people living in the Lake District of England. Hence, the task cannot be completed with the given evidence, and we need to search for another article.\n",
            "\n",
            "Doc: Lake District\n",
            "State: continu\n",
            "文章:威廉 · 華茲渥斯 （ William Wordsworth ) ， 英國浪漫主義詩人 ， 與雪萊 、 拜倫齊名 ， 也是湖畔詩人的代表 ， 曾當上桂冠詩人 。 其代表作有與塞繆爾 · 泰勒 · 柯勒律治合著的 《 抒情歌謠集 》 、 長詩 《 序曲 》 （ Prelude ） 、 《 漫遊 》 （ Excursion ） 。\n",
            "\n",
            "目前正在檢索的文章是:威廉·華茲華斯\n",
            "\n",
            "現在要完成的是事實查核任務：從文章中找出與陳述句相關的句子，也有可能文章中不存在相關的句子。如果文章中的句子沒有陳述句的完整信息，請依照缺失的信息決定下一步需要檢索的文章(文章名稱必須是維基百科頁面，名詞)在思考下一步需要檢索的文章請記得不要是當前檢索的文章(當前檢索的文章名稱是什麼？)。如果思考證據句缺失的信息無法經由檢索其他文章中的句子完成任務則標籤為\"資訊不足\"\n",
            "\n",
            "先完成以上步驟給出思考過程。最後整理答案按照以下格式根據指示輸出：\n",
            "evidence:輸出所有證據句，包含已檢索的證據句以及從文章中檢索得到的證據句。並且不要使用: 數字 以及 · 以及 \n",
            " 來區分每一句話。\n",
            "doc:下一步需要檢索的文章，如果不再進行檢索其他文章則為\"None\"，如果缺失的信息無法經由檢索其他文章中的句子完成任務則標籤為\"Not enough info\"。\n",
            "state:如果需要繼續檢索其他文章則狀態為\"continue\"，如果已經找齊所有證據句則狀態為\"finish\"。\n",
            "\n",
            "System: You are ChatGPT,s large language model trained by OpenAI.\n",
            "Knowledge cutoff:2021-09\n",
            "Current data:[current date]\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\u001b[91m\u001b[1m 當前正在檢索的文章是:威廉·華茲華斯\n",
            "\n",
            "解析證據句:\n",
            "1. \"威廉 · 華茲渥斯 （ William Wordsworth ) ， 英國浪漫主義詩人 ， 與雪萊 、 拜倫齊名 ， 也是湖畔詩人的代表\"\n",
            "   - 這句提到華茲華斯是湖畔詩人的代表，其中提到的湖泊可能指的就是英格蘭湖區，與陳述句相關。\n",
            "2. \"曾當上桂冠詩人。\"\n",
            "   - 這句提到華茲華斯曾擔任過桂冠詩人的職位，但未提及他代表的地區或生活在英格蘭湖區，與陳述句無直接相關性。\n",
            "3. \"其代表作有與塞繆爾 · 泰勒 · 柯勒律治合著的《抒情歌謠集》、長詩《序曲》（Prelude）、《漫遊》（Excursion）。\n",
            "   - 這句提到華茲華斯的代表作，但未提及他代表的地區或生活在英格蘭湖區，與陳述句無直接相關性。 \n",
            "\n",
            "根據已檢索的證據句，只有第一句提及了華茲華斯是湖畔詩人的代表，但並未具體提及他代表的地區是否為英格蘭湖區。因此，需要進一步檢索其他文章以找出更多相關證據。\n",
            "\n",
            "證據字串:\n",
            "1. \"威廉 · 華茲渥斯 （ William Wordsworth ) ， 英國浪漫主義詩人 ， 與雪萊 、 拜倫齊名 ， 也是湖畔詩人的代表\"\n",
            "2. \"曾當上桂冠詩人。\"\n",
            "3. \"其代表作有與塞繆爾 · 泰勒 · 柯勒律治合著的 《 抒情歌謠集 》 、 長詩 《 序曲 》 （ Prelude ） 、 《 漫遊 》 （ Excursion ） 。\"\n",
            "\n",
            "下一步需要檢索的文章是: Lake District\n",
            "狀態: continue \u001b[0m\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new EvidenceRetrivalBot chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mHuman: \n",
            "陳述句:威廉·華茲華斯是生活在英格蘭湖區的民意代表。\n",
            "以檢索的證據句:當前正在檢索的文章是:威廉·華茲華斯\n",
            "\n",
            "解析證據句:\n",
            "1. \"威廉 · 華茲渥斯 （ William Wordsworth ) ， 英國浪漫主義詩人 ， 與雪萊 、 拜倫齊名 ， 也是湖畔詩人的代表\"\n",
            "   - 這句提到華茲華斯是湖畔詩人的代表，其中提到的湖泊可能指的就是英格蘭湖區，與陳述句相關。\n",
            "2. \"曾當上桂冠詩人。\"\n",
            "   - 這句提到華茲華斯曾擔任過桂冠詩人的職位，但未提及他代表的地區或生活在英格蘭湖區，與陳述句無直接相關性。\n",
            "3. \"其代表作有與塞繆爾 · 泰勒 · 柯勒律治合著的《抒情歌謠集》、長詩《序曲》（Prelude）、《漫遊》（Excursion）。\n",
            "   - 這句提到華茲華斯的代表作，但未提及他代表的地區或生活在英格蘭湖區，與陳述句無直接相關性。 \n",
            "\n",
            "根據已檢索的證據句，只有第一句提及了華茲華斯是湖畔詩人的代表，但並未具體提及他代表的地區是否為英格蘭湖區。因此，需要進一步檢索其他文章以找出更多相關證據。\n",
            "\n",
            "證據字串:\n",
            "1. \"威廉 · 華茲渥斯 （ William Wordsworth ) ， 英國浪漫主義詩人 ， 與雪萊 、 拜倫齊名 ， 也是湖畔詩人的代表\"\n",
            "2. \"曾當上桂冠詩人。\"\n",
            "3. \"其代表作有與塞繆爾 · 泰勒 · 柯勒律治合著的 《 抒情歌謠集 》 、 長詩 《 序曲 》 （ Prelude ） 、 《 漫遊 》 （ Excursion ） 。\"\n",
            "\n",
            "下一步需要檢索的文章是: Lake District\n",
            "狀態: continu\n",
            "文章:威廉 · 華茲渥斯 （ William Wordsworth ) ， 英國浪漫主義詩人 ， 與雪萊 、 拜倫齊名 ， 也是湖畔詩人的代表 ， 曾當上桂冠詩人 。 其代表作有與塞繆爾 · 泰勒 · 柯勒律治合著的 《 抒情歌謠集 》 、 長詩 《 序曲 》 （ Prelude ） 、 《 漫遊 》 （ Excursion ） 。\n",
            "\n",
            "目前正在檢索的文章是:威廉·華茲華斯\n",
            "\n",
            "現在要完成的是事實查核任務：從文章中找出與陳述句相關的句子，也有可能文章中不存在相關的句子。如果文章中的句子沒有陳述句的完整信息，請依照缺失的信息決定下一步需要檢索的文章(文章名稱必須是維基百科頁面，名詞)在思考下一步需要檢索的文章請記得不要是當前檢索的文章(當前檢索的文章名稱是什麼？)。如果思考證據句缺失的信息無法經由檢索其他文章中的句子完成任務則標籤為\"資訊不足\"\n",
            "\n",
            "先完成以上步驟給出思考過程。最後整理答案按照以下格式根據指示輸出：\n",
            "evidence:輸出所有證據句，包含已檢索的證據句以及從文章中檢索得到的證據句。並且不要使用: 數字 以及 · 以及 \n",
            " 來區分每一句話。\n",
            "doc:下一步需要檢索的文章，如果不再進行檢索其他文章則為\"None\"，如果缺失的信息無法經由檢索其他文章中的句子完成任務則標籤為\"Not enough info\"。\n",
            "state:如果需要繼續檢索其他文章則狀態為\"continue\"，如果已經找齊所有證據句則狀態為\"finish\"。\n",
            "\n",
            "System: You are ChatGPT,s large language model trained by OpenAI.\n",
            "Knowledge cutoff:2021-09\n",
            "Current data:[current date]\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\u001b[91m\u001b[1m 現在要完成的是事實查核任務。根據已檢索的證據句：\n",
            "\n",
            "證據字串：\n",
            "1. \"威廉 · 華茲渥斯 （ William Wordsworth ) ， 英國浪漫主義詩人 ， 與雪萊 、 拜倫齊名 ， 也是湖畔詩人的代表\"\n",
            "2. \"曾當上桂冠詩人。\"\n",
            "3. \"其代表作有與塞繆爾 · 泰勒 · 柯勒律治合著的 《 抒情歌謠集 》 、 長詩 《 序曲 》 （ Prelude ） 、 《 漫遊 》 （ Excursion ） 。\"\n",
            "\n",
            "從已經檢索的證據句中，可以確定以下內容：\n",
            "- 威廉·華茲華斯是英國浪漫主義詩人，與雪萊和拜倫齊名。\n",
            "- 他是湖畔詩人的代表之一。\n",
            "- 他曾擔任過桂冠詩人的職位。\n",
            "- 華茲華斯的代表作包括《抒情歌謠集》、長詩《序曲》（Prelude）和《漫遊》（Excursion）。\n",
            "\n",
            "根據目前的證據，我們僅提及了華茲華斯是湖畔詩人的代表，但沒有具體提及他生活在英格蘭湖區。為了找到更多相關證據，下一步需要檢索的文章是\"威廉·華茲華斯\"。\n",
            "\n",
            "請注意，目前已完成所有證據句的檢索，並且下一步需要檢索的文章為\"威廉·華茲華斯\"。現在已經完成了證據的查找任務。\n",
            "\n",
            "證據:\n",
            "- 威廉·華茲渥斯 （ William Wordsworth ) ， 英國浪漫主義詩人 ， 與雪萊 、 拜倫齊名 ， 也是湖畔詩人的代表 。\n",
            "- 曾當上桂冠詩人。\n",
            "- 其代表作有與塞繆爾·泰勒·柯勒律治合著的《抒情歌謠集》、長詩《序曲》 （ Prelude ） 、 《漫遊》 （ Excursion ） 。\n",
            "- [已檢索到的文章]威廉·華茲華斯\n",
            "\n",
            "下一步需要檢索的文章: None\n",
            "狀態: 結束 (finish) \u001b[0m\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new EvidenceRetrivalBot chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mHuman: \n",
            "陳述句:威廉·華茲華斯是生活在英格蘭湖區的民意代表。\n",
            "以檢索的證據句:現在要完成的是事實查核任務。根據已檢索的證據句：\n",
            "\n",
            "證據字串：\n",
            "1. \"威廉 · 華茲渥斯 （ William Wordsworth ) ， 英國浪漫主義詩人 ， 與雪萊 、 拜倫齊名 ， 也是湖畔詩人的代表\"\n",
            "2. \"曾當上桂冠詩人。\"\n",
            "3. \"其代表作有與塞繆爾 · 泰勒 · 柯勒律治合著的 《 抒情歌謠集 》 、 長詩 《 序曲 》 （ Prelude ） 、 《 漫遊 》 （ Excursion ） 。\"\n",
            "\n",
            "從已經檢索的證據句中，可以確定以下內容：\n",
            "- 威廉·華茲華斯是英國浪漫主義詩人，與雪萊和拜倫齊名。\n",
            "- 他是湖畔詩人的代表之一。\n",
            "- 他曾擔任過桂冠詩人的職位。\n",
            "- 華茲華斯的代表作包括《抒情歌謠集》、長詩《序曲》（Prelude）和《漫遊》（Excursion）。\n",
            "\n",
            "根據目前的證據，我們僅提及了華茲華斯是湖畔詩人的代表，但沒有具體提及他生活在英格蘭湖區。為了找到更多相關證據，下一步需要檢索的文章是\"威廉·華茲華斯\"。\n",
            "\n",
            "請注意，目前已完成所有證據句的檢索，並且下一步需要檢索的文章為\"威廉·華茲華斯\"。現在已經完成了證據的查找任務。\n",
            "\n",
            "證據:\n",
            "- 威廉·華茲渥斯 （ William Wordsworth ) ， 英國浪漫主義詩人 ， 與雪萊 、 拜倫齊名 ， 也是湖畔詩人的代表 。\n",
            "- 曾當上桂冠詩人。\n",
            "- 其代表作有與塞繆爾·泰勒·柯勒律治合著的《抒情歌謠集》、長詩《序曲》 （ Prelude ） 、 《漫遊》 （ Excursion ） 。\n",
            "- [已檢索到的文章]威廉·華茲華斯\n",
            "\n",
            "下一步需要檢索的文章: None\n",
            "狀態: 結束 (finish\n",
            "文章:威廉 · 華茲渥斯 （ William Wordsworth ) ， 英國浪漫主義詩人 ， 與雪萊 、 拜倫齊名 ， 也是湖畔詩人的代表 ， 曾當上桂冠詩人 。 其代表作有與塞繆爾 · 泰勒 · 柯勒律治合著的 《 抒情歌謠集 》 、 長詩 《 序曲 》 （ Prelude ） 、 《 漫遊 》 （ Excursion ） 。\n",
            "\n",
            "目前正在檢索的文章是:威廉·華茲華斯\n",
            "\n",
            "現在要完成的是事實查核任務：從文章中找出與陳述句相關的句子，也有可能文章中不存在相關的句子。如果文章中的句子沒有陳述句的完整信息，請依照缺失的信息決定下一步需要檢索的文章(文章名稱必須是維基百科頁面，名詞)在思考下一步需要檢索的文章請記得不要是當前檢索的文章(當前檢索的文章名稱是什麼？)。如果思考證據句缺失的信息無法經由檢索其他文章中的句子完成任務則標籤為\"資訊不足\"\n",
            "\n",
            "先完成以上步驟給出思考過程。最後整理答案按照以下格式根據指示輸出：\n",
            "evidence:輸出所有證據句，包含已檢索的證據句以及從文章中檢索得到的證據句。並且不要使用: 數字 以及 · 以及 \n",
            " 來區分每一句話。\n",
            "doc:下一步需要檢索的文章，如果不再進行檢索其他文章則為\"None\"，如果缺失的信息無法經由檢索其他文章中的句子完成任務則標籤為\"Not enough info\"。\n",
            "state:如果需要繼續檢索其他文章則狀態為\"continue\"，如果已經找齊所有證據句則狀態為\"finish\"。\n",
            "\n",
            "System: You are ChatGPT,s large language model trained by OpenAI.\n",
            "Knowledge cutoff:2021-09\n",
            "Current data:[current date]\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\u001b[91m\u001b[1m evidence:\n",
            "- 威廉華茲渥斯（William Wordsworth），英國浪漫主義詩人，與雪萊、拜倫齊名，也是湖畔詩人的代表。\n",
            "- 曾當上桂冠詩人。\n",
            "- 其代表作有與塞繆爾泰勒柯勒律治合著的《抒情歌謠集》、長詩《序曲》（Prelude）、《漫遊》（Excursion）。\n",
            "- 威廉·華茲華斯是英格蘭湖區的民意代表（陳述句）。\n",
            "\n",
            "doc: None\n",
            "state: finish \u001b[0m\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new MyChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mHuman: \n",
            "根據| |前後的雙引號\"\"包圍的一組證據句以及\"\"包圍的陳述句，按照以下步驟以及要求，選擇使用 支持/反駁/資訊不足 來完成三分類任務\n",
            "\n",
            "一、從陳述句和證據句當中抽取出可以互相對應對應的單詞。\n",
            "\n",
            "二、接著檢出每一個對應的單詞，如果含義無法成功匹配，則視為關鍵詞。\n",
            "\n",
            "三、檢查證據句的關鍵詞是否有蘊含陳述句當中的關鍵詞，如果關鍵詞的含義不等同則視為反駁。不等同的狀況請參考以下但不限於以下範例：\"含義明顯衝突、無法經由推論得出結論、蘊含關係不明確。\"參考以上範例根據提供的句子做出合理的判斷。\n",
            "\n",
            "\"evidence:\n",
            "- 威廉華茲渥斯（William Wordsworth），英國浪漫主義詩人，與雪萊、拜倫齊名，也是湖畔詩人的代表。\n",
            "- 曾當上桂冠詩人。\n",
            "- 其代表作有與塞繆爾泰勒柯勒律治合著的《抒情歌謠集》、長詩《序曲》（Prelude）、《漫遊》（Excursion）。\n",
            "- 威廉·華茲華斯是英格蘭湖區的民意代表（陳述句）。\"| |\"威廉·華茲華斯是生活在英格蘭湖區的民意代表。\"\n",
            "\n",
            "根據上下文| |應填入 支持/反駁/資訊不足 ？\n",
            "\n",
            "System: You are ChatGPT,s large language model trained by OpenAI.\n",
            "Knowledge cutoff:2021-09\n",
            "Current data:[current date]\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\u001b[96m\u001b[1m 根據提供的句子，可以得出以下結論：\n",
            "- 陳述句：威廉·華茲華斯是英格蘭湖區的民意代表。\n",
            "- 證據句：威廉華茲渥斯是湖畔詩人的代表，他是英國浪漫主義詩人，擔任過桂冠詩人，並有多部代表作品。\n",
            "\n",
            "進行三分類任務：\n",
            "1. 第一步，抽取出可以互相對應的單詞。根據陳述句和證據句可以對應單詞：\"威廉·華茲華斯\"、\"湖畔詩人的代表\"、\"英國浪漫主義詩人\"、\"桂冠詩人\"、\"代表作品\"。\n",
            "2. 第二步，檢出每個對應單詞的含義是否成功匹配。根據提供的信息，這些對應單詞的含義是成功匹配的，因為他們在陳述和證據句中都指代威廉·華茲華斯以及他在詩歌領域的重要地位和代表作品。\n",
            "3. 第三步，檢查證據句的關鍵詞是否蘊含陳述句的關鍵詞，如果關鍵詞的含義不等同則視為反駁。\n",
            "   - 根據以上關鍵詞的比對，可以確定證據句的關鍵詞 \"英格蘭湖區\" 蘊含陳述句的關鍵詞 \"湖畔詩人的代表\"，因此不屬於反駁。\n",
            "   - 同時，證據句的關鍵詞 \"生活\" 與陳述句的關鍵詞 \"民意代表\" 在含義上也相符，進一步支持陳述句。\n",
            "\n",
            "綜上所述，根據提供的信息，可以判斷該證據句支持陳述句，因此選擇「支持」作為答案。 \u001b[0m\u001b[0m\n"
          ]
        }
      ]
    }
  ]
}