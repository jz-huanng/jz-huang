{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### setup"
      ],
      "metadata": {
        "id": "S09Sl1kGLn8n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive') # 此處需要登入google帳號\n",
        "\n",
        "!git clone https://github.com/IKMLab/NCKU-AICUP2023-baseline\n",
        "%cd NCKU-AICUP2023-baseline\n",
        "!cp -r /content/gdrive/MyDrive/aicup-2023-plain/* ."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yPNnt2uEQKgV",
        "outputId": "5cfbcd34-5768-4f2f-8b18-a66ca1c3acf0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n",
            "Cloning into 'NCKU-AICUP2023-baseline'...\n",
            "remote: Enumerating objects: 146, done.\u001b[K\n",
            "remote: Counting objects: 100% (45/45), done.\u001b[K\n",
            "remote: Compressing objects: 100% (23/23), done.\u001b[K\n",
            "remote: Total 146 (delta 34), reused 30 (delta 22), pack-reused 101\u001b[K\n",
            "Receiving objects: 100% (146/146), 82.78 KiB | 6.90 MiB/s, done.\n",
            "Resolving deltas: 100% (85/85), done.\n",
            "/content/NCKU-AICUP2023-baseline\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cIUoNn0YM7SU",
        "outputId": "6c0ca547-f14f-421f-c525-82bab990be1b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.6/73.6 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m34.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "#!pip install -q ipywidgets pandarallel pandas scikit-learn tqdm opencc wikipedia\n",
        "!pip install -q pandas wikipedia\n",
        "!pip -q install openai langchain #huggingface_hub\n",
        "#!pip install dotenv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from pathlib import Path\n",
        "import os\n",
        "\n",
        "# 3rd party libs\n",
        "import pandas as pd\n",
        "import wikipedia\n",
        "\n",
        "#from dotenv import dotenv_values\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = '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'\n",
        "#os.environ['OPENAI_API_KEY']=dotenv.dotenv_values(.env)[\"OPENAI_API_KEY\"]\n",
        "wikipedia.set_lang(\"zh\")\n",
        "\n",
        "import langchain\n",
        "langchain.debug=False\n"
      ],
      "metadata": {
        "id": "Pibak_jWNEbr"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### functions(wiki...)"
      ],
      "metadata": {
        "id": "tmsC7j7sLdPR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_json(file_path):\n",
        "    with open(file_path, \"r\", encoding=\"utf8\") as json_file:\n",
        "        json_list = list(json_file)\n",
        "    return [json.loads(json_str) for json_str in json_list]\n",
        "\n",
        "def wiki_database(path):\n",
        "\t\tdatabase=pd.concat(\n",
        "        [pd.DataFrame(load_json(file)) for file in Path(path).glob(\"*.jsonl\")]\n",
        "    )\n",
        "\t\treturn dict(zip(database[\"id\"].tolist(),database[\"text\"].tolist()))\n",
        "\n",
        "def get_wiki_text(wiki,key_word):\n",
        "    try:\n",
        "      text=wiki[key_word]\n",
        "    except KeyError:\n",
        "      text=\"KeyError\"\n",
        "    return text\n"
      ],
      "metadata": {
        "id": "DWgEnUIBPmGW"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "WIKI_PATH=\"data/wiki-pages\"\n",
        "\n",
        "wiki=wiki_database(WIKI_PATH)"
      ],
      "metadata": {
        "id": "qVlFZ_eQqcl_"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Build chains"
      ],
      "metadata": {
        "id": "ubyVZcs1NpnM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models.openai import ChatOpenAI\n",
        "from langchain.chains import LLMChain\n",
        "from langchain import PromptTemplate\n",
        "\n",
        "#text-davinci-003\n",
        "MODEL_NAME=\"gpt-3.5-turbo-16k-0613\"\n",
        "llm = ChatOpenAI(model_name=MODEL_NAME, temperature=1.2, max_tokens = 4096)\n",
        "\n",
        "from langchain.prompts.chat import (\n",
        "    ChatPromptTemplate,\n",
        "    SystemMessagePromptTemplate,\n",
        "    AIMessagePromptTemplate,\n",
        "    HumanMessagePromptTemplate,\n",
        ")\n",
        "from langchain.schema import AIMessage, HumanMessage, SystemMessage\n"
      ],
      "metadata": {
        "id": "08DLt9OzNHH1"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyChain(LLMChain):\n",
        "\n",
        "    @classmethod\n",
        "    def from_llm_and_prompt(cls,llm,prompt,verbose=False):\n",
        "        return cls(prompt=prompt, llm=llm, verbose=verbose)"
      ],
      "metadata": {
        "id": "wNZUsAejHC8n"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EvidenceRetrivalBot(LLMChain):\n",
        "    \"\"\"implenment agent concept via chain class\"\"\"\n",
        "\n",
        "    @classmethod\n",
        "    def from_llm_and_prompt(cls,llm,prompt,verbose=False):\n",
        "        return cls(prompt=prompt, llm=llm, verbose=verbose)"
      ],
      "metadata": {
        "id": "R_LaL3bFOhtH"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import PromptTemplate\n",
        "\n",
        "doc_retrieval_template = \"\"\"\n",
        "你是一個看過維基百科內容的機器人，讓我們來預測以下提供的陳述句可能的出處。請從陳述句中選擇一個單字作為檢索的關鍵字。\n",
        "\n",
        "claim:{claim}\n",
        "\n",
        "按照以下格式返回預測的關鍵詞\n",
        "keyword:\n",
        "\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"claim\"],\n",
        "    template=doc_retrieval_template,\n",
        ")\n",
        "\n",
        "doc_chain=MyChain.from_llm_and_prompt(llm=llm,prompt=prompt)\n"
      ],
      "metadata": {
        "id": "oaUakMO5Nv0c"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evidence_selection_template = \"\"\"\n",
        "陳述句:{claim}\n",
        "以檢索的證據句:{evidence}\n",
        "文章:{text}\n",
        "\n",
        "目前正在檢索的文章是:{keyword}\n",
        "\n",
        "現在要完成的是事實查核任務：從文章中找出與陳述句相關的句子，也有可能文章中不存在相關的句子。如果文章中的句子沒有陳述句的完整信息，請依照缺失的信息決定下一步需要檢索的文章(文章名稱必須是維基百科頁面，名詞)在思考下一步需要檢索的文章請記得不要是當前檢索的文章(當前檢索的文章名稱是什麼？)。如果思考證據句缺失的信息無法經由檢索其他文章中的句子完成任務則標籤為\"資訊不足\"\n",
        "\n",
        "先完成以上步驟給出思考過程。最後整理答案按照以下格式根據指示輸出：\n",
        "evidence:輸出所有證據句，包含已檢索的證據句以及從文章中檢索得到的證據句。並且不要使用: 數字 以及 · 以及 \\n 來區分每一句話。\n",
        "label:如果缺失的信息無法藉由檢索其他文章得到，則標籤為\"Not enough info\"，否則無論是否需要進行檢索其他文章，一律為\"None\"。\n",
        "doc:下一步需要檢索的文章，如果不再進行檢索其他文章則為\"None\"。\n",
        "state:如果需要繼續檢索其他文章則狀態為\"continue\"，如果已經找齊所有證據句則狀態為\"finish\"。\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "human_message_prompt = HumanMessagePromptTemplate(\n",
        "        prompt=PromptTemplate(\n",
        "            template=evidence_selection_template,\n",
        "            input_variables=[\"claim\",\"evidence\",\"text\",\"keyword\"],\n",
        "        )\n",
        "    )\n",
        "agent_planning = ChatPromptTemplate.from_messages([human_message_prompt,SystemMessage(\n",
        "        content=\"You are ChatGPT,a large language model trained by OpenAI.\\nKnowledge cutoff:2021-09\\nCurrent data:[current date]\\n\"\n",
        "    )])\n",
        "\n",
        "agent=EvidenceRetrivalBot.from_llm_and_prompt(llm=llm, prompt=agent_planning,verbose=True)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "MPzxSj83Oumw"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "claim_retrieval_template = \"\"\"\n",
        "證據句可能支持或反駁陳述句，以下提供的證據句與陳述句存在微小的差異，而只要有一點意思的的差異就會導致證據句\"反駁\"陳述句。按照以下步驟決定證據句支持或反駁陳述句:\n",
        "\n",
        "接下來請先找出證據句與陳述句之間的決定句子意思的關鍵字，接著仔細思考兩者是否存在差異：\"含義明顯衝突\"、\"無法經由推論得出結論\"、\"蘊含關係不明確\"。若有上述情況發生則視為反駁。\n",
        "\n",
        "請仔細檢查以上的狀況是否有發生，如果不存在則視為支持\n",
        "\n",
        "證據句:{evidence}\n",
        "陳述句:{claim}\n",
        "\n",
        "按照以上步驟決定證據句是支持還是反駁陳述句\n",
        "\"\"\"\n",
        "human_message_prompt = HumanMessagePromptTemplate(\n",
        "        prompt=PromptTemplate(\n",
        "            input_variables=[\"claim\",\"evidence\"],\n",
        "            template=claim_retrieval_template,\n",
        "        )\n",
        "    )\n",
        "claim_retrieval = ChatPromptTemplate.from_messages([human_message_prompt,SystemMessage(\n",
        "        content=\"You are ChatGPT,a large language model trained by OpenAI.\\nKnowledge cutoff:2021-09\\nCurrent data:[current date]\\n\"\n",
        "    )])\n",
        "\n",
        "claimRetrieval=MyChain.from_llm_and_prompt(llm=llm, prompt=claim_retrieval,verbose=True)\n"
      ],
      "metadata": {
        "id": "mqS9JSqiQvme"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### main"
      ],
      "metadata": {
        "id": "Ke342oxSfiOp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "font ref:https://blog.csdn.net/c_lanxiaofang/article/details/126107796"
      ],
      "metadata": {
        "id": "9YEn1L-9Kavx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def keywordParser(keywords):\n",
        "    #\\s | Matches whitespace characters, which include the \\t, \\n, \\r, and space characters.\n",
        "    PATTERN=re.compile(r\"(K|k)eywords?\\s*:?\\s*\\'*\\\"*\")\n",
        "    keyword=re.split(PATTERN,keywords)[-1]\n",
        "    return keyword\n",
        "\n",
        "def getAction(response):\n",
        "    PARSER_START = \"evidence:\"\n",
        "    # find(f'\"{self.generation_marker}\"')\n",
        "    start_parsing = response.find(f\"{PARSER_START}\")\n",
        "    if (start_parsing != -1):\n",
        "        reponse = response[start_parsing:]\n",
        "\n",
        "    LABEL_START_MARKER = \"label:\"\n",
        "    DOC_START_MARKER = \"doc:\"\n",
        "    STATE_START_MARKER = \"state:\"\n",
        "\n",
        "    label_start = response.find(LABEL_START_MARKER)\n",
        "    doc_start = response.find(DOC_START_MARKER)\n",
        "    state_start = response.find(STATE_START_MARKER)\n",
        "\n",
        "    evidence = response[:label_start]\n",
        "    evidence = re.split(r\"evidence:\\n*\\t*\\s*\", evidence)[-1].strip()\n",
        "    label = response[label_start:doc_start]\n",
        "    label = re.split(r\"label:\\n*\\t*\\s*\", label)[-1].strip()\n",
        "    doc = response[doc_start:state_start]\n",
        "    doc = re.split(r\"doc:\\\"*\\n*\\t*\\s*\", doc)[-1].split(\"或\")[0].strip()\n",
        "    state = response[state_start:]\n",
        "    state = re.split(r\"state:\\n*\\t*\\s*\", state)[-1].strip()\n",
        "\n",
        "    return evidence,label,doc, state\n"
      ],
      "metadata": {
        "id": "6sQKzUMNeP3I"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def refreshState():\n",
        "\t\tlabel=\"None\"\n",
        "\t\tdoc=\"None\"\n",
        "\t\tstate=\"None\"\n",
        "\t\treturn label,doc,state"
      ],
      "metadata": {
        "id": "wkVbocuNQJ3J"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "Ct6KI-lfjY-u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"***************************************************\")\n",
        "claim=claim=input(\"請輸入一個陳述句:\")\n",
        "\n",
        "text=\"KeyError\"\n",
        "evidence=\"需要從以下文章中檢索\"\n",
        "\n",
        "while(text==\"KeyError\"):\n",
        "    keywords=doc_chain.run(claim)\n",
        "    keyword=keywordParser(keywords)\n",
        "    text=get_wiki_text(wiki,keyword)\n",
        "\n",
        "while True:\n",
        "    label,doc,state=refreshState()\n",
        "    response=agent.run(claim=claim,evidence=evidence,keyword=keyword,text=text)\n",
        "    print(\"\\033[91m\\033[1m\" ,response, \"\\033[0m\\033[0m\")\n",
        "    evidence,label,doc,state=getAction(response)\n",
        "    #print(\"evidence:\",evidence,\"\\ndoc:\",doc)\n",
        "\n",
        "    IS_FINISH=(state==\"finish\" and doc==\"None\")\n",
        "    NOT_ENOUGH_INFO=(label==\"Not enough info\" or (doc==keyword and state==\"finish\"))\n",
        "    IS_CONTINUE=(state==\"continue\")\n",
        "\n",
        "    if IS_FINISH:\n",
        "        answer=claimRetrieval.run(claim=claim,evidence=evidence)\n",
        "        print(\"\\033[96m\\033[1m\" ,answer, \"\\033[0m\\033[0m\")\n",
        "        break\n",
        "\n",
        "    if NOT_ENOUGH_INFO:\n",
        "        print(\"\\033[90m\\033[1m\" + \"claim:\",claim,\"is NOT ENOUGH INFO\" \"\\033[0m\\033[0m\")\n",
        "        break\n",
        "\n",
        "    if IS_CONTINUE:\n",
        "        if get_wiki_text(wiki,doc)!=\"KeyError\":\n",
        "            text=wiki[doc]\n",
        "        #evidence=evidence\n",
        "        continue\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "00kBB3Diet93",
        "outputId": "4b707efe-30c9-4b97-cd56-0e87c6626aff"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "***************************************************\n",
            "請輸入一個陳述句:中國人馮端的主要研究方向是原子排列具有隨機性結構的晶體。\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new EvidenceRetrivalBot chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mHuman: \n",
            "陳述句:中國人馮端的主要研究方向是原子排列具有隨機性結構的晶體。\n",
            "以檢索的證據句:需要從以下文章中檢索\n",
            "文章:Infobox country | native_name = | conventional_long_name = 馬來西亞 | image_flag = Flag of Malaysia.svg | alt_flag = | image_coat = Coat of arms of Malaysia.svg | alt_coat = | other_symbol = 國花 ： 木槿 、 大紅花 | image_map = Location_Malaysia_ASEAN. svg | map_width = 250px | image_map3 = Malaysia in the world ( W3 ). svg | map_caption3 = 馬來西亞在世界上的位置 | alt_map = | map_caption = | image_map2 = File: Malaysia_on_the_globe _ ( Southeast_Asia_centered ). svg | alt_map2 = | map_caption2 = 馬來西亞在東半球的位置 | ethnic_groups = | ethnic_groups_year = 2021 | religion = | leader_name1 = 蘇丹阿都拉陛下 | sovereignty_type = 從大英帝國獨立 | established_event1 = 馬來亞聯合邦獨立 | established_date1 = 1957年8月31日 | established_event2 = 新加坡自治 | established_date2 = 1959年6月3日 | established_event3 = 砂拉越自治 | established_date3 = 1963年7月22日 | established_event4 = 北婆羅州自治 | established_date4 = 1963年8月31日 | established_date5 = 1963年9月16日 | established_date6 = 1965年8月9日 | military_personnel = 109,000 | military_personnel_rank = 45 | military_personnel_year = 2022 | military_personnel_ref = | area_rank = 第67名 | area_km2 = 329,847 | area_footnote = | percent_water = 0.3 | population_estimate = 33,871,431 | population_estimate_rank = 44 | population_estimate_year = 2022 | population_census = | population_census_year = | population_census_rank = | population_density_km2 = 99.01 | population_density_rank = 116 | GDP_PPP = 10,894.99 億美元 | GDP_PPP_rank = 29 | GDP_PPP_year = 2022 | GDP_PPP_per_capita_rank = 51 | GDP_nominal = 4,393.73 億美元 | GDP_nominal_rank = 39 | GDP_nominal_year = 2022 | GDP_nominal_per_capita_rank = 60 | Gini = 41 | Gini_rank = | Gini_year = 2015 | Gini_ref = | Gini_change = decrease | HDI = 0.810 | HDI_rank = 62 | HDI_year = 2020年 | HDI_ref = | HDI_change = increase | currency_code = MYR | utc_offset = +08:00 | date_format = dd / mm / yyyy | cctld =. my | iso3166code = MY | calling_code = +60 | footnote_a = 馬來西亞伊斯蘭教以遜尼派爲正宗 ， 什葉派爲非法教派 。 | footnote_b = 馬來西亞基督教是包含馬來西亞境內東正教 、 天主教和新教等基督教宗派的總稱 。 | official_website = 馬來西亞最高元首爲君主立憲制國家元首 ， 由馬來統治者會議選出 ， 任期五年 。 政府則由獲得最多國會議席的政黨或聯盟的領袖 - 首相所領導 ， 政治體 - { 制 } - 沿襲自英國的 - { zh - cn: 威斯敏斯特; zh - hk: 西敏; zh - tw: 西敏; } -- { 制 } - 度 。\n",
            "\n",
            "目前正在檢索的文章是:馬來西亞\n",
            "\n",
            "現在要完成的是事實查核任務：從文章中找出與陳述句相關的句子，也有可能文章中不存在相關的句子。如果文章中的句子沒有陳述句的完整信息，請依照缺失的信息決定下一步需要檢索的文章(文章名稱必須是維基百科頁面，名詞)在思考下一步需要檢索的文章請記得不要是當前檢索的文章(當前檢索的文章名稱是什麼？)。如果思考證據句缺失的信息無法經由檢索其他文章中的句子完成任務則標籤為\"資訊不足\"\n",
            "\n",
            "先完成以上步驟給出思考過程。最後整理答案按照以下格式根據指示輸出：\n",
            "evidence:輸出所有證據句，包含已檢索的證據句以及從文章中檢索得到的證據句。並且不要使用: 數字 以及 · 以及 \n",
            " 來區分每一句話。\n",
            "label:如果缺失的信息無法藉由檢索其他文章得到，則標籤為\"Not enough info\"，否則無論是否需要進行檢索其他文章，一律為\"None\"。\n",
            "doc:下一步需要檢索的文章，如果不再進行檢索其他文章則為\"None\"。\n",
            "state:如果需要繼續檢索其他文章則狀態為\"continue\"，如果已經找齊所有證據句則狀態為\"finish\"。\n",
            "\n",
            "System: You are ChatGPT,a large language model trained by OpenAI.\n",
            "Knowledge cutoff:2021-09\n",
            "Current data:[current date]\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\u001b[91m\u001b[1m 首先，我們檢查要找的陳述句：\"中國人馮端的主要研究方向是原子排列具有隨機性結構的晶體。\"\n",
            "\n",
            "根據目前已經提供的文章 \"馬來西亞\"，我們無法在這篇文章中找到與陳述句相關的證據句。因此，我們需要進一步檢索其他文章。\n",
            "\n",
            "下一步，我們將搜索有關「中國人馮端的研究領域」的資訊，以了解他的主要研究領域和任何相關信息。\n",
            "\n",
            "doc:冶金學\n",
            "\n",
            "state:continue \u001b[0m\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new EvidenceRetrivalBot chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mHuman: \n",
            "陳述句:中國人馮端的主要研究方向是原子排列具有隨機性結構的晶體。\n",
            "以檢索的證據句:首先，我們檢查要找的陳述句：\"中國人馮端的主要研究方向是原子排列具有隨機性結構的晶體。\"\n",
            "\n",
            "根據目前已經提供的文章 \"馬來西亞\"，我們無法在這篇文章中找到與陳述句相關的證據句。因此，我們需要進一步檢索其他文章。\n",
            "\n",
            "下一步，我們將搜索有關「中國人馮端的研究領域」的資訊，以了解他的主要研究領域和任何相關信息。\n",
            "\n",
            "doc:冶金學\n",
            "\n",
            "state:continu\n",
            "文章:冶金學 （ metallurgy ） 屬於材料科學 ， 是研究從礦石中提取金屬 ， 並用各種加工方法制成具有一定性能的金屬材料的學科 。 冶金學也研究金屬 、 金屬互化物或其混合物 （ 稱爲合金 ） 的物理及化學特性 。 冶金學也是一門金屬的技術 ， 有關金屬製造的科學 ， 也和金屬零件的工程特性有關 。 金屬的製造包括從礦石中提煉金屬 ， 以及金屬混合物 （ 或金屬和其他元素的混合物 ） 以製造合金 。 冶金學和金屬加工的工藝不同 ， 不過金屬加工和冶金學有關 ， 正如隨著技術的發展 ， 醫學和醫學科學有關一樣 。 冶金學可以分爲鋼鐵冶金學 （ 有時也稱爲黑色冶金學 ） 及非鐵金屬冶金學 （ 有時也稱爲有色金屬冶金學 ） 。 鋼鐵冶金學是有關鐵的合金及其製造 ， 而非鐵金屬冶金學是以不含鐵的合金及其製造爲主 ， 世界上的金屬生產中 ， 鐵 、 鈷 、 鎳及其有關合金的黑色金屬佔了95 %\n",
            "\n",
            "目前正在檢索的文章是:馬來西亞\n",
            "\n",
            "現在要完成的是事實查核任務：從文章中找出與陳述句相關的句子，也有可能文章中不存在相關的句子。如果文章中的句子沒有陳述句的完整信息，請依照缺失的信息決定下一步需要檢索的文章(文章名稱必須是維基百科頁面，名詞)在思考下一步需要檢索的文章請記得不要是當前檢索的文章(當前檢索的文章名稱是什麼？)。如果思考證據句缺失的信息無法經由檢索其他文章中的句子完成任務則標籤為\"資訊不足\"\n",
            "\n",
            "先完成以上步驟給出思考過程。最後整理答案按照以下格式根據指示輸出：\n",
            "evidence:輸出所有證據句，包含已檢索的證據句以及從文章中檢索得到的證據句。並且不要使用: 數字 以及 · 以及 \n",
            " 來區分每一句話。\n",
            "label:如果缺失的信息無法藉由檢索其他文章得到，則標籤為\"Not enough info\"，否則無論是否需要進行檢索其他文章，一律為\"None\"。\n",
            "doc:下一步需要檢索的文章，如果不再進行檢索其他文章則為\"None\"。\n",
            "state:如果需要繼續檢索其他文章則狀態為\"continue\"，如果已經找齊所有證據句則狀態為\"finish\"。\n",
            "\n",
            "System: You are ChatGPT,a large language model trained by OpenAI.\n",
            "Knowledge cutoff:2021-09\n",
            "Current data:[current date]\n",
            "\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.llms.base:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo-16k in organization org-5qGjvC0WBRN73RMlAjaYOEMG on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\u001b[91m\u001b[1m 根據目前已提供的文章 \"冶金學\"，我們找不到與陳述句相關的證據句。因此，我們需要進一步檢索其他文章。\n",
            "\n",
            "下一步，我們將搜索有關「中國人馮端的研究領域」的資訊，以了解他的主要研究領域和任何相關信息。\n",
            "\n",
            "doc:凝聚態物理學\n",
            "\n",
            "state:continue \u001b[0m\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new EvidenceRetrivalBot chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mHuman: \n",
            "陳述句:中國人馮端的主要研究方向是原子排列具有隨機性結構的晶體。\n",
            "以檢索的證據句:根據目前已提供的文章 \"冶金學\"，我們找不到與陳述句相關的證據句。因此，我們需要進一步檢索其他文章。\n",
            "\n",
            "下一步，我們將搜索有關「中國人馮端的研究領域」的資訊，以了解他的主要研究領域和任何相關信息。\n",
            "\n",
            "doc:凝聚態物理學\n",
            "\n",
            "state:continu\n",
            "文章:凝聚態物理學專門研究物質凝聚相的物理性質 。 該領域的研究者力圖通過物理學定律來解釋凝聚相物質的行爲 。 其中 ， 量子力學 、 電磁學以及統計力學的相關定律對於該領域尤爲重要 。 固相以及液相是人們最爲熟悉的凝聚相 。 除了這兩種相之外 ， 凝聚相還包括一些特定的物質在低溫條件下的超導相 、 自旋有關的鐵磁相及反鐵磁相 、 超低溫原子系統的玻色 - 愛因斯坦凝聚相等等 。 對於凝聚態的研究包括通過實驗手段測定物質的各種性質 ， 以及利用理論方法發展數學模型以深入理解這些物質的物理行爲 。 由於尚有大量的系統及現象亟待研究 ， 凝聚態物理學成爲了目前物理學最爲活躍的領域之一 。 僅在美國 ， 該領域的研究者就佔到該國物理學者整體的近三分之一 ， 凝聚態物理學部也是美國物理學會最大的部門 。 此外 ， 該領域還與化學 ， 材料科學以及納米技術等學科領域交叉 ， 並與原子物理學以及生物物理學等物理學分支緊密相關 。 該領域研究者在理論研究中所採用的一些概念與方法也適用於粒子物理學及核物理學等領域 。 晶體學 、 冶金學 、 彈性力學以及磁學等等起初是各自獨立的學科領域 。 這些學科在二十世紀四十年代被物理學家統合爲固體物理學 。 時間進入二十世紀六十年代後 ， 有關液體物理性質的研究也被納入其中 ， 形成凝聚態物理學這一新學科 。 據物理學家菲利普 · 安德森所述 ， 術語 “ 凝聚態物理學 ” 是他和首創 。 1967年 ， 他們把位於卡文迪許實驗室的研究組名稱由 “ 固體理論 ” 改爲 “ 凝聚態理論 ” 。 二人覺得原來的名稱並沒有涵蓋液體及等方面研究 。 但是 ， “ 凝聚態 ” 這一術語此前已在歐洲學界出現 ， 只是由他們普及而已 。 較爲著名的例子是施普林格公司於1963年創建的期刊 《 凝聚態物理學 》 （ Physics of Condensed Matter ） 。 二十世紀六 、 七十年代的資金環境以及各國政府採取的冷戰政策促使相關領域物理學家接納了 “ 凝聚態物理學 ” 這一術語 。 他們認爲這一術語相對於 “ 固體物理學 ” 而言更爲突出了固體 、 液體 、 等離子體以及其他複雜物質研究之間的共通性 。 這些研究與金屬和半導體在工業上的應用息息相關 。 貝爾實驗室是最早開展凝聚態物理學研究項目的研究機構之一 。 “ 凝聚態 ” 這一術語在更早的文獻中即已出現 。 例如 ， 在1947年出版的由雅科夫 · 弗倫克爾撰寫的專著 《 液體動力學理論 》 （ Kinetic theory of liquids ） 的緒論中 ， 他提出 ： “ 液體動力學理論日後也將發展爲固體動力學理論的推廣與延伸 。 實際上 ， 更爲正確的做法或許是將液體與固體統歸爲‘凝聚體 ’ 。 ”\n",
            "\n",
            "目前正在檢索的文章是:馬來西亞\n",
            "\n",
            "現在要完成的是事實查核任務：從文章中找出與陳述句相關的句子，也有可能文章中不存在相關的句子。如果文章中的句子沒有陳述句的完整信息，請依照缺失的信息決定下一步需要檢索的文章(文章名稱必須是維基百科頁面，名詞)在思考下一步需要檢索的文章請記得不要是當前檢索的文章(當前檢索的文章名稱是什麼？)。如果思考證據句缺失的信息無法經由檢索其他文章中的句子完成任務則標籤為\"資訊不足\"\n",
            "\n",
            "先完成以上步驟給出思考過程。最後整理答案按照以下格式根據指示輸出：\n",
            "evidence:輸出所有證據句，包含已檢索的證據句以及從文章中檢索得到的證據句。並且不要使用: 數字 以及 · 以及 \n",
            " 來區分每一句話。\n",
            "label:如果缺失的信息無法藉由檢索其他文章得到，則標籤為\"Not enough info\"，否則無論是否需要進行檢索其他文章，一律為\"None\"。\n",
            "doc:下一步需要檢索的文章，如果不再進行檢索其他文章則為\"None\"。\n",
            "state:如果需要繼續檢索其他文章則狀態為\"continue\"，如果已經找齊所有證據句則狀態為\"finish\"。\n",
            "\n",
            "System: You are ChatGPT,a large language model trained by OpenAI.\n",
            "Knowledge cutoff:2021-09\n",
            "Current data:[current date]\n",
            "\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.llms.base:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo-16k in organization org-5qGjvC0WBRN73RMlAjaYOEMG on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\u001b[91m\u001b[1m evidence: \n",
            "\n",
            "1. 凝聚態物理學專門研究物質凝聚相的物理性質。\n",
            "2. 量子力學、電磁學以及統計力學的相關定律對於該領域尤爲重要。\n",
            "3. 凝聚物相包括固相、液相以及特定物質的超導相、自旋有關的鐵磁相及反鐵磁相、超低溫原子系統的玻色-愛因斯坦凝聚相等。\n",
            "4. 凝聚態物理學的研究包括實驗手段測定物質性質和發展數學模型以深入理解物理行爲。\n",
            "5. 凝聚態物理學與化學、材料科學以及納米技術等學科領域交叉，與其他物理學分支也有關聯。\n",
            "\n",
            "label: None\n",
            "doc: None\n",
            "state: finish \u001b[0m\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new MyChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mHuman: \n",
            "證據句可能支持或反駁陳述句，以下提供的證據句與陳述句存在微小的差異，而只要有一點意思的的差異就會導致證據句\"反駁\"陳述句。按照以下步驟決定證據句支持或反駁陳述句:\n",
            "\n",
            "接下來請先找出證據句與陳述句之間的決定句子意思的關鍵字，接著仔細思考兩者是否存在差異：\"含義明顯衝突\"、\"無法經由推論得出結論\"、\"蘊含關係不明確\"。若有上述情況發生則視為反駁。\n",
            "\n",
            "請仔細檢查以上的狀況是否有發生，如果不存在則視為支持\n",
            "\n",
            "證據句:1. 凝聚態物理學專門研究物質凝聚相的物理性質。\n",
            "2. 量子力學、電磁學以及統計力學的相關定律對於該領域尤爲重要。\n",
            "3. 凝聚物相包括固相、液相以及特定物質的超導相、自旋有關的鐵磁相及反鐵磁相、超低溫原子系統的玻色-愛因斯坦凝聚相等。\n",
            "4. 凝聚態物理學的研究包括實驗手段測定物質性質和發展數學模型以深入理解物理行爲。\n",
            "5. 凝聚態物理學與化學、材料科學以及納米技術等學科領域交叉，與其他物理學分支也有關聯。\n",
            "陳述句:中國人馮端的主要研究方向是原子排列具有隨機性結構的晶體。\n",
            "\n",
            "按照以上步驟決定證據句是支持還是反駁陳述句\n",
            "\n",
            "System: You are ChatGPT,a large language model trained by OpenAI.\n",
            "Knowledge cutoff:2021-09\n",
            "Current data:[current date]\n",
            "\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.llms.base:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo-16k in organization org-5qGjvC0WBRN73RMlAjaYOEMG on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "WARNING:langchain.llms.base:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo-16k in organization org-5qGjvC0WBRN73RMlAjaYOEMG on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\u001b[96m\u001b[1m 根据所提供的证据句和陈述句，我们将进行以下步骤来确定证据句是支持还是反驳陈述句：\n",
            "\n",
            "1. 检查关键字和关键信息: \n",
            "\n",
            "   - 证据句的关键信息是凝聚态物理学专门研究物质凝聚相的物理性质，涵盖了固相、液相以及特定物质的超导相、自旋有关的铁磁相和反铁磁相、超低温原子系统的玻色-爱因斯坦凝聚相等。这与晶体的随机排列结构的研究方向并无直接关联。\n",
            "  \n",
            "   - 陈述句的关键信息是中国人冯端的主要研究方向是原子排列具有随机性结构的晶体。\n",
            "   \n",
            "2. 比较含义是否明显冲突: \n",
            "\n",
            "   直接比较证据句和陈述句的关键信息，发现证据句中提到的凝聚态物理学的研究范畴与陈述句中的晶体随机排列的研究方向没有明显的冲突。\n",
            "   \n",
            "3. 是否无法通过推论得出结论:\n",
            "\n",
            "   通过关键信息的比较，可以通过推论得出陈述句中的研究方向可能与凝聚态物理学的某些方面存在关联，但是没有足够的线索来确定具体的联系。\n",
            "   \n",
            "4. 蘊含关系是否不明确:\n",
            "\n",
            "   根据所提供的证据句和陈述句，没有明确说明二者之间的蕴含关系。\n",
            "   \n",
            "根据以上步骤的分析，我们没有找到明显的差异或冲突，也没有确定的证据来支持或反驳陈述句。因此，根据目前提供的信息，我们无法确定证据句是支持还是反驳陈述句。请提供更多相关信息以进一步分析。 \u001b[0m\u001b[0m\n"
          ]
        }
      ]
    }
  ]
}